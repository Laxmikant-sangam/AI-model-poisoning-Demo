# AI-model-poisoning-Demo
Adversarial AI lab.  Demonstrates how small  changes to input data can  trick a Machine Learning model
